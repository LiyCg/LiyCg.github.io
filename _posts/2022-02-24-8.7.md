---
title:  "8.7 Decision Tree / Regression Tree"
categories: 
  - ML_practice
tags:
  - machine learning
  - ML
  - Tree
  - Decision Tree
  - Regression Tree
toc: true
toc_sticky: true
toc_label: "Decision Tree / Regression Tree"
toc_icon: "blog"
---



## 8.7 Decision Tree
#### - Concepts and Definition
#### 의사결정하는데 tree를 이용함
#### 확률변수의 불확실한 정도 측정에 쓰이는 '엔트로피'를 이용
#### - 작동과정
#### 1) feature 별로 test를 진행 ex) 날씨, 바람, 온도 등
#### 2) 각 결과(맑음, 흐림, 비)에 해당하는 target을 결과노드에 포함시킴
#### 3) Entropy(d) = -sigma(i~k){P(i|d)log2(P(i|d))} / 를 이용하여 구함 (214pg참고)
#### 4) 각 결과노드별 엔트로피를 이용, 테스트 전체의 성능을 평가 (215pg참고)
#### 5) 각 테스트별로 성능평가해서 가장 낮은 엔트로피(좋은 성능)를 가진 테스트를 선정
#### 6) 선정된 테스트의 결과 결과 노드중 정확한 prediction을 하지 못하는 노드에 대해 추가로 feature별 테스트 진행(선정된 feature제외)
#### 7) 5)과 동일한 과정으로 다음 테스트 선정
#### 8) 모든 결과 노드들이 정확한 prediction을 할때까지 1)부터 반복
____________________________________________________________
#### 8.7.4 Regression Tree(Decision Tree whose target is continuous)
#### - Concepts and Definition
#### 의사결정 tree의 'target'이 연속형 변수인 tree
#### cf) 'feature'가 연속형일 경우엔, decision tree를 사용하되 각 피처값을 따로 테스트 기준으로 정하고 테스트한다.(220pg참고) 
#### - 작동과정
#### 예측값은 KNN에서 target이 continuous할 때와 마찬가지로 각 target의 평균값으로 예측한다!
____________________________________________________________
#### Pros : 모델을 이해하기 용이하다
#### cons : 오버피팅의 위험이 높다
#### => 이 단점을 보완위해 '랜덤 포레스트' 방법이 있음. chapter 9에서 살펴보자. 





```python
# wine 분류 model을 만들어보자!

from sklearn import datasets
raw_wine = datasets.load_wine()

X = raw_wine.data
y = raw_wine.target

from sklearn.model_selection import train_test_split
X_tn, X_te, y_tn, y_te = train_test_split(X,y,random_state=0)

from sklearn.preprocessing import StandardScaler
std_scale = StandardScaler()
std_scale.fit(X_tn)
X_tn_std = std_scale.transform(X_tn)
X_te_std = std_scale.transform(X_te)

# data training(learning)
from sklearn import tree
# 만약 regression 문제일 경우, DecisionTreeRegressor를 사용하자!!
clf_tree = tree.DecisionTreeClassifier(random_state=0)
clf_tree.fit(X_tn_std,y_tn)

# prediction
pred_tree = clf_tree.predict(X_te_std)
print(pred_tree)

# f1 score evaluation
from sklearn.metrics import f1_score
f1 = f1_score(y_te, pred_tree, average = 'macro')
print(f1)

# confusion matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_te, pred_tree)
print(cm)

# class- report
from sklearn.metrics import classification_report
cr = classification_report(y_te, pred_tree)
print(cr)

```

    [0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 1 0 1 1 1 1 1 1 1 2 0 0 1 0 0 0 2
     1 1 2 1 0 1 1 1]
    0.9349141206870346
    [[14  2  0]
     [ 0 20  1]
     [ 0  0  8]]
                  precision    recall  f1-score   support
    
               0       1.00      0.88      0.93        16
               1       0.91      0.95      0.93        21
               2       0.89      1.00      0.94         8
    
        accuracy                           0.93        45
       macro avg       0.93      0.94      0.93        45
    weighted avg       0.94      0.93      0.93        45
    

